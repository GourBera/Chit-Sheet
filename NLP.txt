from nltk.tokenize import sent_tokenize, word_tokenize

stop = stopwords.words('english') + list(string.punctuation)
words = [i for i in word_tokenize(token.lower()) if i not in stop]

nltk.FreqDist(words) 



[blob = TextBlob()]

blob.words
blob.sentences

.pluralize()
.correct()
.spellcheck()
.translate(from_lang="zh-CN", to='en')
.detect_language()
.ngrams(n=3)

Part-of-speech Tagging: 
blob.tags