Bracket vs Dot Notation
& vs |
list(df)

Count NA Value:
	df.na().sum()

Missing data handling:

dropna(axis=0, how={'any','all'}, thresh=None)
fillna(value={'col1': 1, 'col2': 3}, method={'ffil','bfil'})
interpolate(method={'polynomial','linear'}, order=2)
replace()



Combining, joining, merging:

* ==> Merge

	The merge method allows you to combine two DataFrames based on one or more common columns between them. It is similar to a SQL join.

master = sales.merge(visits, how="inner", sort=True)	# how= {'left','right,'outer','inner'}
master = pd.merge(
    sales,
    visits,
    on=['country', 'Year', 'Month'],
    suffixes=('_left', '_right'),
    how="inner", 
    sort=True)


* ==> Join
	The join method is a more convenient way to combine DataFrames based on their indexes.

result = df1.join(df2) 	
master = sales.join(
    visits,
    # Wont Work on=['country'],
    lsuffix='_left',
    rsuffix='_right',
    how="inner",
    sort=True)


* ==> Append
	used to concatenate two or more DataFrames along the row axis

master = sales.append(visits, ignore_index=True, sort=True)


* ==> Concat
	pd.concat function to concatenate two or more DataFrames along a specified axis. 
	By default, the axis parameter is set to 0, which means the DataFrames will be 
	concatenated vertically, row-wise.

master = pd.concat([sales, visits], ignore_index=True, sort=True, axis=0)


* ==> assign(new_col=func) => Assign new columns to a DataFrame.
	master = sales.assign(next_5_year = sales["Year"] + 5)

	def next_cycle(value):
	    return value + next_cycle_value

	master = sales.assign(next_cycle = next_cycle(sales["Year"]))


* => 	update()
	The pd.update() method is used to update the values of one DataFrame with the values from another DataFrame


* => 	Add a new column with same data
	master["new_col"] = "hello,hello,hello"


Functions:

* ==> get_dummies(drop_first=)
	convert categorical variables into dummy/indicator variables

	master = pd.get_dummies(master, columns=['country'], prefix='prefix')

* ==> unique()
	master["Month"].unique()

* ==> nunique()
	master["Month"].nunique()




Reshaping, sorting, transposing:

droplevel()
pivot(index='col1', columns='col2', values='col3') => reshaped DataFrame
sort_values(by=['col1','col2'], ascending=False, kind:{'quicksort','mergesort','heapsort'})
melt(id_vars=[('col1', 'col2')], value_vars=[('B', 'E')]) =>  wide format to long format
sort_index(level=)
stack(level=)
unstack(level=)
T (transpose)
df.groupby('A').pipe(lambda x: x.max() - x.min())
nlargest(3) => top 3
nsmallest()
most_commons()




idmax()
idmin()

df.filter(like='bbi', axis=0)
df.filter(regex='e$', axis=1)

df.equals(df2)

pd.date_range('1/1/2010', periods=6, freq='D')
df.reset_index(level='class', col_level=1, col_fill='genus')

DataFrame:
get_dtype_counts()


df.isin([0, 2])
df.isin({'num_wings': [0, 3]})



s.where(s > 1, 10) => Replace with 10
>> m = df % 3 == 0
>> df.where(m, -df) => all df negative except m

df.query('a > b')

notna()
astype('int64') => type cast

*insert(loc, column, value, allow_duplicates=False)

get_dummies(drop_first=True)
concat(axis=1)

to_datetime(format='%Y%m%d', errors='ignore')
.dt.date
value_counts().idxmax()


Read:
read_sql(query, engine)
read_table('.tsv')



--------------------
DataFrame.index => get row count
DataFrame.columns => get column count
DataFrame.shape => get row and column sount


-------NA
isna => Detect missing values
notna => Detect existing (non-missing) values
isnull()
notnull()

duplicated()

copy(deep=True) => copy df

-------LOC/ILOC
df.loc[['viper', 'sidewinder']] => Access a group of rows and columns by label
df.iloc[:3] => integer-location based indexing

-------ITERATOR
iteritems => iter over columns
iterrows => iter over rows

query => query over df



-------APPLY/MAP
apply => Apply a function along an axis of the DataFrame.
applymap => Apply a function to a Dataframe elementwise.

-------AGG/GROUPBY
df.agg(['sum', 'min']) => Aggregate using one or more operations
df.groupby(['Animal']).mean() => Group DataFrame or Series
df.groupby(level=1).mean() => Multi index

corr => pairwise correlation of columns


-------DROP
df.drop(columns=['B', 'C'], axis=1)
drop_duplicates => keep='first'
duplicated

-------INDEX
reindex(['a','b'])
rename => df.rename(str.lower, axis='columns')

set_index => df.set_index('month')

-------MISSING VALUE
Missing data handling:
dropna(axis=0, how={‘any’, ‘all’}, thresh=None, inplace=False)
fillna(method={'ffill', 'backfill'})








pd.melt(df2, id_vars='Country') => Except country column
value_counts(normalize = True) => returns the %



a = np.array([1,2,3,4])
b = np.array([5,6,7,8])
np.column_stack((a,b)) #[[1,5],[2,6],[3,7],[4,8]]

https://khuyentran1401.github.io/Efficient_Python_tricks_and_tools_for_data_scientists/Chapter5/better_pandas.html#overwrite-partitions-of-a-pandas-dataframe



