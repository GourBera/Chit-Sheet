Regularization l1, l2
unstructure data classification
api development to derive data
high biyas vs high variance =>

high biyas (underfit) -> Training error and validation error will be high
high variance (overfit) -> Training error will be low, but validation error will be high


Uniform distribution -> no mode (uniformly distributed, all data points are same)
Median is best for highly skewed distribution

TF-IDF =>
Term Frequency Inverse Document Frequency

Normalization = feature - (subtracting the mean and then dividing the std)
TF-IDF, n-gram
Fourier Transformation
ASCII
logging

NLTK, pyaudio, struct, Textblob, 



df.column
df.keys()
list(df)



bias (how well the model fits the data) and variance (how much the model changes based on changes in the inputs).



df.query('action == "click"').id.nunique()
df[['A','B','C','D']] = pd.get_dummies(df.prestige)



df.drop(['prestige','D'],axis = 1, inplace=True)



df['intercept'] = 1

logit_mod = sm.Logit(df['admit'], df[['intercept', 'gre','gpa','A','B','C']])
result = logit_mod.fit()
result.summary()

df['intercept'] = 1

mod = sm.OLS(df.price, df[['intercept','carats']])
result = mod.fit()
result.summary()



MSCS

I had programming knowledge from the begining as I worked as an automation engineer, then I started learning Python and I facinated by the simplicity of the language, I felt very easy to learn and I can do a lot more than java very easily

import statsmodels.api as sm

data['intercept'] = 1

lm = sm.OLS(data['Detergents_Paper'], data[['intercept','Fresh', 'Milk', 'Grocery', 'Frozen', 'Delicatessen']])
results = lm.fit()
results.summary()



df[['A','B','C']] = pd.get_dummies(df['neighborhood'])
df[['ranch','victorian','lodge']] = pd.get_dummies(df['style'])

df['style'].unique()

df['intercept'] = 1
lm = sm.OLS( df['price'], df[['area', 'bedrooms', 'bathrooms','A','B','C','ranch','victorian','lodge']])
result = lm.fit()
summary = result.summary()
summary



def dummy_cat(df, col):
    '''
    INPUT:
    df - the dataframe where col is stored
    col - the categorical column you want to dummy (as a string)
    OUTPUT:
    df - the dataframe with the added columns
         for dummy variables using 1, 0, -1 coding
    '''
    for idx, val_0 in enumerate(df[col].unique()):
        if idx + 1 < df[col].nunique():            
            df[val_0] = df[col].apply(lambda x: 1 if x == val_0 else 0)
        else:    
            df[val_0] = df[col].apply(lambda x: -1 if x == val_0 else 0)
            for idx, val_1 in enumerate(df[col].unique()):
                if idx + 1 < df[col].nunique():
                    df[val_1] = df[val_0] + df[val_1]
                else:
                    del df[val_1]
    return df


new_df = dummy_cat(df, 'style') # Use on style
new_df.head(10)

new_df['intercept'] = 1

lm = sm.OLS(new_df['price'], new_df[['intercept', 'ranch', 'victorian']])
results = lm.fit()
results.summary()


style_dummies = pd.get_dummies(df['style'])
new_df2 = df2.join(style_dummies)
new_df2.head(10)


new_df2['intercept'] = 1

lm2 = sm.OLS(new_df2['price'], new_df2[['intercept', 'ranch', 'victorian']])
results2 = lm2.fit()
results2.summary()








log_mod = LogisticRegression()
log_mod.fit(X_train, y_train)
preds = log_mod.predict(X_test)
confusion_matrix(y_test, preds) 


precision_score(y_test, preds) 

recall_score(y_test, preds)

accuracy_score(y_test, preds)

from ggplot import *
from sklearn.metrics import roc_curve, auc
%matplotlib inline

preds = log_mod.predict_proba(X_test)[:,1]
fpr, tpr, _ = roc_curve(y_test, preds)

df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))
ggplot(df, aes(x='fpr', y='tpr')) +\
    geom_line() +\
    geom_abline(linetype='dashed')













https://career-resource-center.udacity.com/interview-courses-and-guides/machine-learning
https://career-resource-center.udacity.com/interviews
https://docs.google.com/document/d/1TNLwa_ThJlliCk6Dk-_bkZU3ZMZOTEmezE2eX7i9rEg/pub?embedded=true
https://elitedatascience.com/machine-learning-interview-questions-answers
https://interviewing.io
https://www.interviewbit.com






















 
